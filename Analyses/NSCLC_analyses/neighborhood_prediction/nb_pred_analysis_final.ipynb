{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dfef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import copy\n",
    "\n",
    "from random import choices\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import data\n",
    "from train import NeighborSupervisedModule\n",
    "\n",
    "import importlib\n",
    "importlib.reload(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b135f02b-55f1-4d7e-9c3b-444fb3d01660",
   "metadata": {},
   "source": [
    "# Load model, make predictions, compute gene importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7be9110-cdca-4176-81ca-256c19792b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = '../../../cache/lightning_logs'\n",
    "\n",
    "# model_dir = '2024_04_11_gut_in_enterocyte_out_goblet'\n",
    "# input_type = 'Enterocyte'\n",
    "# target_type = 'Goblet'\n",
    "\n",
    "# model_dir = '2024_04_11_gut_in_goblet_out_enterocyte'\n",
    "# input_type = 'Goblet'\n",
    "# target_type = 'Enterocyte'\n",
    "\n",
    "# model_dir = '2024_04_11_nsclc_in_fibroblast_out_tumor'\n",
    "# input_type = 'fibroblast'\n",
    "# target_type = 'tumor'\n",
    "\n",
    "# model_dir = '2024_04_11_nsclc_in_tumor_out_fibroblast'\n",
    "# input_type = 'tumor'\n",
    "# target_type = 'fibroblast'\n",
    "\n",
    "# model_dir = '2024_04_11_nsclc_in_macrophage_out_fibroblast'\n",
    "# input_type = 'macrophage'\n",
    "# target_type = 'fibroblast'\n",
    "\n",
    "model_dir = '2024_04_11_nsclc_in_neutrophil_out_tumor'\n",
    "input_type = 'neutrophil'\n",
    "target_type = 'tumor'\n",
    "\n",
    "with open(os.path.join(model_base, model_dir, 'hparams.yaml'), 'r') as stream:\n",
    "    params_yaml = yaml.unsafe_load(stream) # Note: use safe_load instead if the yaml is not trusted.\n",
    "params = params_yaml['params']\n",
    "loaders, in_dim, out_dim, class_counts, class_names, gene_list = data.get_loaders(params)\n",
    "model = NeighborSupervisedModule.load_from_checkpoint(os.path.join(model_base, model_dir, 'checkpoints', 'last.ckpt'), map_location='cpu')\n",
    "\n",
    "# This notebook assumes we're working with logistic regression.\n",
    "assert params['enc_depth'] == 0\n",
    "\n",
    "# This notebook assumes we're using a single output class.\n",
    "assert params['class_names_whitelist'] is not None\n",
    "assert len(params['class_names_whitelist']) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9d87a45-7d8b-4748-80ce-7e7f7f64c80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ecole/anaconda3/envs/torch_py39/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=2)`.\n",
      "  rank_zero_warn(\n",
      "/home/ecole/anaconda3/envs/torch_py39/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:490: PossibleUserWarning: Your `predict_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████| 73/73 [00:00<00:00, 699.25it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████| 49/49 [00:00<00:00, 771.85it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████| 35/35 [00:00<00:00, 722.56it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(accelerator='cpu', inference_mode=True)\n",
    "preds = {}\n",
    "targs = {}\n",
    "ids = {}\n",
    "for phase in ['train', 'val', 'test']:\n",
    "    results = trainer.predict(model, loaders[phase])\n",
    "    all_preds = []\n",
    "    all_targs = []\n",
    "    all_ids = []\n",
    "    for batch in results:\n",
    "        cur_preds, cur_targs, cur_ids = batch\n",
    "        cur_preds = torch.sigmoid(cur_preds)\n",
    "        all_preds.append(cur_preds.numpy())\n",
    "        all_targs.append(cur_targs.numpy())\n",
    "        try:\n",
    "            # throws an error for nsclc val set, why?\n",
    "            all_ids.append(cur_ids.numpy())\n",
    "        except AttributeError as e:\n",
    "            all_ids.append(cur_ids)\n",
    "    preds[phase] = np.concatenate(all_preds, axis=0)\n",
    "    targs[phase] = np.concatenate(all_targs, axis=0)\n",
    "    ids[phase] = np.concatenate(all_ids, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e982d77-bdc7-46ec-8916-01bd615db47e",
   "metadata": {},
   "source": [
    "# Extract gene importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f00bf0ff-2eb3-41e3-9c01-917cf7020673",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_importance = trainer.model.model.head.weight.detach().numpy().ravel()\n",
    "# Note: If we use raw values, then the most important genes will be those that are strongly enriched.\n",
    "# We could also take the absolute value, which would rank genes as important if they're strongly enriched or depleted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a1a36-161c-4fa7-a37e-06317df43646",
   "metadata": {},
   "source": [
    "# Save results to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "001d4422-095d-4ffe-9a1a-25629df3bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame({'gene': gene_list, 'importance_score': gene_importance})\n",
    "df_out.sort_values(by='importance_score', inplace=True, ascending=False)\n",
    "df_out.to_csv(f'../../../cache/nb_pred_{model_dir}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15148869-1a9d-4d5d-9886-e0112442216e",
   "metadata": {},
   "source": [
    "# Visualize splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e30829-6884-4c04-b071-540aad16b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_splits():\n",
    "    all_coords, all_inputs, all_targs, all_ids, all_class_names, all_gene_list, all_focal_cell_type = data.parse_data(params)\n",
    "    df = pd.DataFrame({'x': all_coords[:, 0], 'y': all_coords[:, 1], 'ids': all_ids})\n",
    "    df['split'] = np.nan\n",
    "    df.loc[df['ids'].isin(ids['train']), 'split'] = 'train'\n",
    "    df.loc[df['ids'].isin(ids['val']), 'split'] = 'val'\n",
    "    df.loc[df['ids'].isin(ids['test']), 'split'] = 'test'\n",
    "    df = df[df['split'] != np.nan]\n",
    "    sns.scatterplot(data=df, x='x', y='y', s=1.0, hue='split')\n",
    "visualize_splits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dbc1c2-4f5f-4297-bae4-ace492612c7c",
   "metadata": {},
   "source": [
    "# Test if the model's test performance is significantly better than chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a478749e-13b3-4e05-a82c-ef2b0ea42119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap null distribution:\n",
    "n_bootstrap = int(1e4)\n",
    "pop = np.ravel(targs['test'])\n",
    "bootstrap_estimates = []\n",
    "for i in range(n_bootstrap):\n",
    "    cur_bootstrap_sample = choices(population=pop, k=len(pop))\n",
    "    bootstrap_estimates.append(np.mean(cur_bootstrap_sample))\n",
    "bootstrap_estimates = np.array(bootstrap_estimates)\n",
    "# compute p value:\n",
    "observed_value = average_precision_score(pop, np.ravel(preds['test']))\n",
    "p = np.mean(bootstrap_estimates > observed_value)\n",
    "plt.hist(bootstrap_estimates)\n",
    "plt.axvline(observed_value, color='k', label='observed')\n",
    "plt.axvline(np.mean(pop), color='r', label='null point estimate')\n",
    "plt.legend()\n",
    "print(f'p-value: {p}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium-workflow",
   "language": "python",
   "name": "xenium-workflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
