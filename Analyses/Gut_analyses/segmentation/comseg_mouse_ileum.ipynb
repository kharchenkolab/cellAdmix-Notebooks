{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import scanpy as sc\n",
    "import random\n",
    "import comseg\n",
    "import comseg.dataset\n",
    "from comseg import dictionary\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../scripts/')\n",
    "\n",
    "from paths import get_data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = get_data_paths('../../../data_mapping.yml')['mouse_gut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = datetime.datetime.now()\n",
    "date_str = f\"{e.month}_d{e.day}_h{e.hour}_min{e.minute}_s{e.second}_r\" + str(random.randint(0, 5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cell_radius = 8\n",
    "mean_cell_diameter = 10\n",
    "\n",
    "path_dataset_folder = data_path / \"comseg_format\"\n",
    "##path to your prior segmentation mask\n",
    "path_to_mask_prior = path_dataset_folder\n",
    "\n",
    "# path_dict_cell_centroid = args.path_dict_cell_centroid\n",
    "\n",
    "\n",
    "path_save = str(path_dataset_folder / (\"results/\" + date_str + \"/\"))\n",
    "Path(path_save).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### writie the argument to a file\n",
    "# with open(Path(path_save) / \"script_parameter.txt\", \"w\") as f:\n",
    "#     for k, v in locals().items():\n",
    "#         f.write(f\"{k} : {v}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add prior to data\n",
      "prior added to data and saved in csv file\n",
      "dict_centroid added for data \n"
     ]
    }
   ],
   "source": [
    "dict_scale = {\"x\": 0.17, 'y': 0.17, \"z\": 1.5}\n",
    "\n",
    "### create the dataset object\n",
    "dataset = comseg.dataset.ComSegDataset(\n",
    "    path_dataset_folder=path_dataset_folder,\n",
    "    path_to_mask_prior=path_to_mask_prior,\n",
    "    dict_scale=dict_scale,\n",
    "    mask_file_extension=\".tif\",\n",
    "    mean_cell_diameter=mean_cell_diameter,\n",
    "    prior_name='in_nucleus'\n",
    ")\n",
    "\n",
    "dataset.add_prior_from_mask(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image name :  data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:44<00:00, 44.93s/it]\n",
      "100%|██████████| 241/241 [00:18<00:00, 13.29it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.compute_edge_weight(  # in micrometer\n",
    "    images_subset=None,\n",
    "    n_neighbors=40,\n",
    "    sampling=True,\n",
    "    sampling_size=10000\n",
    ")\n",
    "corr_matrix = []\n",
    "np.save(path_to_mask_prior /'dict_co_expression_n40_50000.npy', dataset.dict_co_expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comsegdict = dictionary.ComSegDict(\n",
    "    dataset=dataset,\n",
    "    mean_cell_diameter=mean_cell_diameter,\n",
    "    community_detection=\"with_prior\"\n",
    ")\n",
    "\n",
    "Comsegdict.compute_community_vector()\n",
    "\n",
    "Comsegdict.compute_insitu_clustering(\n",
    "    size_commu_min=3,\n",
    "    norm_vector=True,\n",
    "    ### parameter clustering\n",
    "    n_pcs=3,\n",
    "    n_comps=3,\n",
    "    clustering_method=\"leiden\",\n",
    "    n_neighbors=20,\n",
    "    resolution=1,\n",
    "    n_clusters_kmeans=4,\n",
    "    palette=None,\n",
    "    nb_min_cluster=0,\n",
    "    min_merge_correlation=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = {}\n",
    "for i in range(-1, 500):\n",
    "    palette[str(i)] = \"#\" + \"%06x\" % random.randint(0, 0xFFFFFF)\n",
    "adata = Comsegdict.in_situ_clustering.anndata_cluster\n",
    "adata.obs[\"leiden_merged\"] = adata.obs[\"leiden_merged\"].astype(int)\n",
    "# sc.tl.umap(adata)\n",
    "# sc.pl.umap(adata, color=[\"leiden_merged\"], palette=palette, legend_loc='on data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 819665/819665 [00:01<00:00, 745604.34it/s]\n",
      "100%|██████████| 1/1 [00:25<00:00, 25.78s/it]\n"
     ]
    }
   ],
   "source": [
    "Comsegdict.add_cluster_id_to_graph(clustering_method=\"leiden_merged\")\n",
    "\n",
    "### get a csv spot/cluster\n",
    "\n",
    "gene_list = []\n",
    "x_list = []\n",
    "y_list = []\n",
    "z_list = []\n",
    "leiden = []\n",
    "cell_id = []\n",
    "\n",
    "img_name = list(Comsegdict.keys())[0]\n",
    "for node in Comsegdict[img_name].G.nodes:\n",
    "    gene_list.append(Comsegdict[img_name].G.nodes[node][\"gene\"])\n",
    "    x_list.append(Comsegdict[img_name].G.nodes[node][\"x\"])\n",
    "    y_list.append(Comsegdict[img_name].G.nodes[node][\"y\"])\n",
    "    z_list.append(Comsegdict[img_name].G.nodes[node][\"z\"])\n",
    "    leiden.append(Comsegdict[img_name].G.nodes[node][\"leiden_merged\"])\n",
    "\n",
    "dictio = {'gene': gene_list, 'x': x_list, 'y': y_list,  'z': z_list,\n",
    "            \"leiden\": leiden}\n",
    "df = pd.DataFrame(dictio)\n",
    "\n",
    "df.to_csv(Path(path_save) / \"leiden0.csv\")\n",
    "\n",
    "Comsegdict.classify_centroid(\n",
    "    path_cell_centroid=None,\n",
    "    n_neighbors=15,\n",
    "    dict_in_pixel=True,\n",
    "    max_dist_centroid=None,\n",
    "    key_pred=\"leiden_merged\",\n",
    "    distance=\"ngb_distance_weights\",\n",
    "    file_extension=\".tiff.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480609/480609 [00:01<00:00, 368900.97it/s]\n",
      "100%|██████████| 1/1 [08:09<00:00, 489.69s/it]\n"
     ]
    }
   ],
   "source": [
    "Comsegdict.associate_rna2landmark(\n",
    "    key_pred=\"leiden_merged\",\n",
    "    distance='distance',\n",
    "    max_cell_radius=max_cell_radius\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list = []\n",
    "x_list = []\n",
    "y_list = []\n",
    "z_list = []\n",
    "leiden = []\n",
    "cell_index_pred_list = []\n",
    "\n",
    "img_name = list(Comsegdict.keys())[0]\n",
    "for node in Comsegdict[img_name].G.nodes:\n",
    "    gene_list.append(Comsegdict[img_name].G.nodes[node][\"gene\"])\n",
    "    x_list.append(Comsegdict[img_name].G.nodes[node][\"x\"])\n",
    "    y_list.append(Comsegdict[img_name].G.nodes[node][\"y\"])\n",
    "    z_list.append(Comsegdict[img_name].G.nodes[node][\"z\"])\n",
    "    leiden.append(Comsegdict[img_name].G.nodes[node][\"leiden_merged\"])\n",
    "    cell_index_pred_list.append(Comsegdict[img_name].G.nodes[node][\"cell_index_pred\"])\n",
    "\n",
    "dictio = {'gene': gene_list, 'x': x_list, 'y': y_list, 'z': z_list,\n",
    "            \"leiden\": leiden, \"cell\": cell_index_pred_list}\n",
    "df = pd.DataFrame(dictio)\n",
    "df.to_csv(Path(path_save) / \"cell0_r10_rmax8_small_p.csv\")\n",
    "\n",
    "adata = Comsegdict.in_situ_clustering.anndata_cluster\n",
    "adata.obs[\"leiden_merged\"] = adata.obs[\"leiden_merged\"].astype(int)\n",
    "#sc.tl.umap(adata)\n",
    "#fig_ledien = sc.pl.umap(adata, color=[\"leiden_merged\"], palette=palette, legend_loc='on data',\n",
    "    #                       )\n",
    "### vizulaize  point cloud with napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polygons?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even alpha 1.0 doesn't help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_anndata, dict_json_img = Comsegdict.anndata_from_comseg_result(alpha=1.0, allow_disconnected_polygon=True)\n",
    "# filename = Path(path_save) / \"result.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 8290 × 240\n",
       "    obs: 'img_name', 'index_commu', 'nb_rna', 'leiden', 'leiden_merged'\n",
       "    var: 'features'\n",
       "    uns: 'pca', 'neighbors', 'leiden'\n",
       "    obsm: 'X_pca'\n",
       "    varm: 'PCs'\n",
       "    obsp: 'distances', 'connectivities'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.16608492493884697)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(final_anndata.uns['df_spots']['data'].cell_index_pred == 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_anndata.write_h5ad(Path(path_save) / \"result.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_anndata.uns['df_spots']['data'].copy()\n",
    "del df['Unnamed: 0']\n",
    "df.to_csv(Path(path_save) / \"segmentation.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium-workflow",
   "language": "python",
   "name": "xenium-workflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
